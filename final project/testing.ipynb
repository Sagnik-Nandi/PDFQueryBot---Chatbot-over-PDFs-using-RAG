{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6V47_t_VLeXx"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).to(torch_device)\n"
      ],
      "metadata": {
        "id": "SYTcb0q8LjGk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode context the generation is conditioned on\n",
        "model_inputs = tokenizer('I enjoy walking with my cute dog', return_tensors='pt').to(torch_device)\n",
        "\n",
        "# generate 40 new tokens\n",
        "greedy_output = model.generate(**model_inputs, max_new_tokens=40)\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "vn7ewfptOW4T",
        "outputId": "c8f85f99-752b-457b-a8b1-311647872ed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
            "\n",
            "I'm not sure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# activate beam search and early_stopping\n",
        "sample_outputs = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=100,\n",
        "    do_sample=True,\n",
        "    temperature=0.5,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    num_return_sequences=3\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "id": "vKJIYzciPGBO",
        "outputId": "39426e0e-3905-4e78-dced-46caccad59ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I enjoy walking with my cute dog. I'm not sure if he likes it or not. I'm sure he's going to love it. I'm sure he's going to love it. I'm sure he's going to love it. I'm sure he's going to love it. I'm sure he's going to love it. I'm sure he's going to love it. I'm sure he's going to love it. I'm sure he's going to love it. I'm sure he's going to love\n",
            "1: I enjoy walking with my cute dog and I love to see him run and play. I love to play with my dog and I love to see him run and play.\n",
            "\n",
            "I love to play with my dog and I love to see him run and play. I love to play with my dog and I love to see him run and play.\n",
            "\n",
            "I love to play with my dog and I love to see him run and play. I love to play with my dog and I love to see him run and play.\n",
            "\n",
            "2: I enjoy walking with my cute dog, but I'm a little concerned about the fact that he's going to be a lot older. I'm just hoping that he's not going to be a problem.\n",
            "\n",
            "I'm not sure how many people I've met who were afraid of being gay. I'm not sure if it's because of their fears, or maybe they're just scared of being gay.\n",
            "\n",
            "I'm not sure if it's because of their fears, or maybe they're just scared of being gay. I\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}