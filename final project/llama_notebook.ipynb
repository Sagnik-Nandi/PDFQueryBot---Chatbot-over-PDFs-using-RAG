{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sagnik-Nandi/PDFQueryBot---Chatbot-over-PDFs-using-RAG/blob/main/final%20project/llama_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Smart Assistant Bot for Document Queries Using Llama 3 8b model and Groq api"
      ],
      "metadata": {
        "id": "Hp629Qmmyox8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "References :\n",
        "- [https://colab.research.google.com/github/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#scrollTo=x4Mkw0lQ7v7I]\n",
        "- [https://jayant017.medium.com/rag-q-a-chatbot-using-openai-langchain-chromadb-and-gradio-536945dd92f9]\n",
        "- [https://www.youtube.com/watch?v=MUJUXmz2i6U](Rag chatbot with gradio)"
      ],
      "metadata": {
        "id": "fnwAOuErqn3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "x6t9f6Kgy7HT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wPhzCmLt5u2Z"
      },
      "outputs": [],
      "source": [
        "!pip install groq -q\n",
        "!pip install langchain -q\n",
        "!pip install langchain_chroma -q\n",
        "!pip install langchain_community -q\n",
        "!pip install langchain_groq -q\n",
        "# !pip install grandalf -q\n",
        "# !pip install numpy -q\n",
        "# !pip install pandas -q\n",
        "!pip install pypdf -q\n",
        "# !pip install sentence-transformers -q #takes 2 min to exec\n",
        "!pip install groq-gradio -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "89VW6T7G-TDj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # To suppress huggingface warnings\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from groq import Groq"
      ],
      "metadata": {
        "id": "1VWWq3OX60-F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Here comes the model\n",
        "embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "rag_llm = ChatGroq(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    temperature = 0.1,\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkeP3ftJAuEP",
        "outputId": "557ff0e7-e71b-4304-e6fb-dcae37c64424"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-38dd284e6a28>:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the pdf -\n",
        "The UGrulebook has been taken as an example for this notebook"
      ],
      "metadata": {
        "id": "q-kagQ9SzCSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "#Loading\n",
        "pdf_path = \"./ugrulebook.pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "docs = loader.load() # list of pages"
      ],
      "metadata": {
        "id": "Fq0-YkhkBC_N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting\n",
        "# split a long document into smaller chunks that can fit into your model's context window\n",
        "# 2 hyperparameters : chunk size and overlap\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators = [\"\\n \\n\",\n",
        "        \" \\n\",\n",
        "        \" \",\n",
        "        \"\",],\n",
        "    keep_separator=False,\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=200\n",
        "  )\n",
        "docs_spl = text_splitter.split_documents(docs)\n",
        "for doc in docs_spl:\n",
        "  doc.page_content = doc.page_content.replace(\"\\n\",\"\") # remove the \\n\n",
        "len(docs_spl)\n",
        "docs_spl[10].page_content"
      ],
      "metadata": {
        "id": "0PlXiTUG-no4",
        "outputId": "5c8826b3-13b7-494f-ed05-caeef61c6410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'their final year. At various stages of the pr ogramme, students are initiated into research methodologies, reading and interpreting research papers, use of engineering and scientific equipments/ instruments, mod-ern computational techniques, writing technical and scientific reports and effective communication. Apart from the minimum credit requirements for the award of the degree, opportunities exist for supplementing the learning experience by crediting additional courses, in diverse areas. These ad-ditional credits, when they are in focused areas, can earn the studentsâ€™ credentials like Minor/ Hon-ours. The requirements for degree programmes run by the Institute are broadly classified as: a) Institute Requirements  (further divided into Compulsory courses, Elective courses and other requirements). b) Departmental Requirements  (further divided into Compulsory courses, Elective courses and other requirements). The curriculum for various programmes are available on the Institute website: www.iitb.ac.in'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "# Storing\n",
        "vectorstore = Chroma.from_documents(docs_spl, embedding=embed_model, collection_name=\"groq_rag\") # takes one min to run\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "kfheTSg4Drk1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = await retriever.ainvoke(\"What are the eligibility criteria for applying for a change of branch/ programme?\")\n",
        "# res[0].page_content.replace(\"\\n\",\"\")\n",
        "res[0].page_content = \"\".join(res[0].page_content.split('\\n'))\n",
        "res[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "1lx-1HBACX8q",
        "outputId": "838cd6f3-a1ed-4066-e825-743f71cc65fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'there are valid requests. E) All changes of branch can b e effected only once at the beginning of the second academic year. No application for change of branch during the subsequent academic years will be entertained. F) Branch change decisions will be final and will not be reversed. G) To run the LASE programme, the minimum student strength for the LASE programme should be 10. If less than 10 students are allotted the LASE programme after branch change then the result will be considered as null and void.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the rag chain"
      ],
      "metadata": {
        "id": "IBG3tjf_zVuQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oC-Uqa747v7I"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from typing import List, Dict\n",
        "\n",
        "RAG_SYSTEM_PROMPT = \"\"\"\\\n",
        "You are an assistant for question-answering tasks. \\\n",
        "Use the following pieces of retrieved context given within delimiters to answer the human's questions.\n",
        "```\n",
        "{context}\n",
        "```\n",
        "If you don't know the answer, just say that you don't know.\\\n",
        "\"\"\" # adapted from https://smith.langchain.com/hub/rlm/rag-prompt-llama3\n",
        "\n",
        "RAG_HUMAN_PROMPT = \"{input}\"\n",
        "\n",
        "RAG_PROMPT = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", RAG_SYSTEM_PROMPT),\n",
        "    (\"human\", RAG_HUMAN_PROMPT)\n",
        "])\n",
        "\n",
        "def format_docs(docs: List[Document]):\n",
        "    \"\"\"Format the retrieved documents\"\"\"\n",
        "    return \"\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever | format_docs, # Use retriever to retrieve docs from vectorstore -> format the documents into a string\n",
        "        \"input\": RunnablePassthrough() # Propogate the 'input' variable to the next step\n",
        "    }\n",
        "    | RAG_PROMPT # format prompt with 'context' and 'input' variables\n",
        "    | rag_llm # get response from LLM using the formatteed prompt\n",
        "    | StrOutputParser() # Parse through LLM response to get only the string response\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = await rag_chain.ainvoke(\"What are the time for holding lectures for first year UG students ?\")\n",
        "res = \"\".join(res.split('\\n'))\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zT8htR6ZE9tU",
        "outputId": "2a8cf4ba-4e6a-451d-8d06-a39be9e72082"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'According to the given context, the lectures for first-year UG students are to be held ONLY between 8:30 am and 5:30 pm and only on working days.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = await rag_chain.ainvoke(\"How many candidates does IIT Bombay take in annually ?\")\n",
        "res = \"\".join(res.split('\\n'))\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "gxD-e6cUKZMe",
        "outputId": "a468230d-7c6b-42b7-a1e0-f6fed9b3c3ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'According to the provided context, IIT Bombay on an average annually admits:* More than 1000 candidates for undergraduate programmes (B.Tech./Dual Degree and B.S.) through the Joint Entrance Examination (JEE)* More than 30 candidates for B.Des. Programme through the Undergraduate Common Entrance Exam for Design (UCEED)* Around 300 candidates for M.Sc. and M.Sc. Ph.D. Dual Degree programmes* More than 1000 candidates for postgraduate programmes* Around 300 candidates for Ph.D. programmes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = await rag_chain.ainvoke(\"What are the requirements of getting a degree ?\")\n",
        "res = \"\".join(res.split('\\n'))\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "lStmYq0EKZ0Q",
        "outputId": "7e0dc131-bd7b-42ef-82da-3b546f410eb8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'According to the provided context, the requirements for degree programmes at the Institute are broadly classified as:a) Institute Requirements:\\t* Compulsory courses\\t* Elective courses\\t* Other requirementsb) Departmental Requirements:\\t* Compulsory courses\\t* Elective courses\\t* Other requirementsAdditionally, the student must:* Take and pass all the courses prescribed for the degree under the general institutional and departmental requirements* Satisfactorily fulfill other academic requirements such as practical training, NSS/NSO/NCC, work visits, seminar, and projects, as specified for the discipline/programme* Pay all the Institute duesFor Dual Degree students, they must also complete the requirements for Honours, as prescribed by the department, which may be different from those prescribed for a B.Tech. student.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = await rag_chain.ainvoke(\"Explain the organisational structure for academic matters.\")\n",
        "res = \"\".join(res.split('\\n'))\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "TAYHn720KakL",
        "outputId": "b8961c3e-4198-45c5-817b-e5a0cf07e9fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'According to the provided context, the organisational structure for academic matters at the Institute is as follows:* The Senate is the supreme body that governs all academic matters of the Institute. It is a statutory body that approves rules and regulations for academic programmes.* The Senate has two Institute-level sub-committees:\\t+ Undergraduate Programmes Committee (UGPC) for undergraduate programmes\\t+ Post-Graduate Programmes Committee (PGPC) for post-graduate programmes* The Dean of Academic Programmes (Dean, AP) and the Associate Dean of Academic Programmes (Associate Dean, AP) are the Conveners & Co-conveners respectively of these committees.* The Senate also has two Institute-level committees for performance and evaluation:\\t+ Undergraduate Academic Performance Evaluation Committee (UGAPEC)\\t+ Postgraduate Academic Performance Evaluation Committee (PGAPEC)* Conveners for these committees are designated from among Senate members.* Each department has two department-level committees:\\t+ Department Undergraduate Committee (DUGC) for undergraduate programmes\\t+ Department Postgraduate Committee (DPGC) for post-graduate programmes* The Head of the Department is the convener of both these departmental committees.* The Senate as well as its sub-committees have student representatives.* The Academic Office, with a Joint/Deputy Registrar (Academic) as in-charge, provides administrative backup for all academic matters.* Each student is assigned a Faculty Adviser from their Department, who guides them on academic matters and helps them complete their courses of study in a timely manner.This organisational structure ensures that academic matters are handled in a coordinated and structured manner, with multiple layers of oversight and decision-making authority.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = await rag_chain.ainvoke(\"What is SPI and what is CPI ? Refer to the Glossary\")\n",
        "res = \"\".join(res.split('\\n'))\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "mAECu158K3QV",
        "outputId": "3f9f73b3-c615-46a1-a543-9e43f2ea342f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'According to the provided context, SPI stands for Semester Performance Index, which is a number that indicates the performance of a student in a semester. It is the weighted average of the grade points obtained in all the courses registered by the student during the semester.CPI stands for Cumulative Performance Index, which is an up-to-date assessment of the overall performance of a student from the time they entered the Institute. It considers all the courses registered by the student, towards the minimum requirement of the degree they have enrolled for, since they entered the Institute. The CPI is calculated at the end of every semester to two decimal places.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Function calls and Gradio"
      ],
      "metadata": {
        "id": "dd54JppFzlmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_docs(path):\n",
        "    loader = PyPDFLoader(file_path=path)\n",
        "    docs = loader.load_and_split(text_splitter=RecursiveCharacterTextSplitter(chunk_size = 1000,\n",
        "                                                                                chunk_overlap = 200,\n",
        "                                                                                length_function = len,\n",
        "                                                                                is_separator_regex=False))\n",
        "    vectorstore = Chroma.from_documents(documents=docs,embedding= embed_model, persist_directory=\"output/general_knowledge\")\n",
        "    return vectorstore\n",
        "\n",
        "def answer_query(message, chat_history):\n",
        "    vectorstore = Chroma(persist_directory=\"output/general_knowledge\", embedding_function=embed_model)\n",
        "    retriever = vectorstore.as_retriever()\n",
        "\n",
        "    rag_chain = (\n",
        "        {\n",
        "            \"context\": retriever | format_docs, # Use retriever to retrieve docs from vectorstore -> format the documents into a string\n",
        "            \"input\": RunnablePassthrough() # Propogate the 'input' variable to the next step\n",
        "        }\n",
        "        | RAG_PROMPT # format prompt with 'context' and 'input' variables\n",
        "        | rag_llm # get response from LLM using the formatteed prompt\n",
        "        | StrOutputParser() # Parse through LLM response to get only the string response\n",
        "\n",
        "    )\n",
        "\n",
        "    response = rag_chain.invoke(message)\n",
        "    chat_history.append((message, response))\n",
        "    return \"\", chat_history\n"
      ],
      "metadata": {
        "id": "k4Db3CS4a0Ao"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import groq_gradio\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.HTML(\"<h1 align = 'center'>Smart Assistant</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "\n",
        "        upload_files = gr.File(label = 'Upload a PDF',file_types=['.pdf'],file_count='single')\n",
        "\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox(label = \"Enter your question here\")\n",
        "    upload_files.upload(add_docs,upload_files)\n",
        "    msg.submit(answer_query,[msg,chatbot],[msg,chatbot])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "Wg2vVt7NFKdV",
        "outputId": "7bf785ea-41c9-4a91-a092-4b7031f4f072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d706eef2d600fb6b2b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d706eef2d600fb6b2b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rGznwFZ0HpRX"
      },
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}