{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sagnik-Nandi/PDFQueryBot---Chatbot-over-PDFs-using-RAG/blob/main/assnmt%202%20-%20Sentiment%20Classifier/sentiment_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data and Installing Dependencies"
      ],
      "metadata": {
        "id": "3SbZLlw3ts3B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "C87F18KQMVAb",
        "outputId": "72155c2e-b5e7-446a-8e61-e34d4b32d43b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls drive/MyDrive/'Colab Notebooks'/'WiDS 2024'\n",
        "# !pip uninstall torchtext torch -y\n",
        "# !pip install torch==2.2.0 torchtext==0.17.0\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import vocab\n",
        "from gensim.utils import tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "# nltk.download('wordnet')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "jvpQUnsAMy5E",
        "outputId": "5511ed67-fffe-4115-8cbe-9a79b694fdf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GsI8mUYP7_NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"drive/MyDrive/Colab Notebooks/WiDS 2024/reviews.csv\")\n",
        "df['sentiment'] = df['sentiment'].map({'positive':1, 'negative':0})\n",
        "\n",
        "for i in range(5):\n",
        "  rev=df.iloc[i]['review']\n",
        "  # iloc gives the i'th row, if you dont use iloc it will try to find a column/feature named i and raise an error\n",
        "  print(rev)\n",
        "  # print(list(tokenize(rev)))\n",
        "  print(\"No of paras:\", len(rev.split('<br /><br />')))\n",
        "  print(\"No of sentences:\", len(rev.split('.')))\n",
        "  print(\"No of words:\", len(rev.split()))\n",
        "  print(\"Label:\", df.iloc[i]['sentiment'])\n",
        "\n",
        "print(max(df['review'].apply(lambda x: len(x.split()))))\n",
        "print(min(df['review'].apply(lambda x: len(x.split()))))"
      ],
      "metadata": {
        "id": "w3BLK6RbNohR",
        "outputId": "0d38232b-99ff-4d78-ef74-3f3d4e059289",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "No of paras: 4\n",
            "No of sentences: 27\n",
            "No of words: 307\n",
            "Label: 1\n",
            "A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n",
            "No of paras: 4\n",
            "No of sentences: 7\n",
            "No of words: 162\n",
            "Label: 1\n",
            "I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.\n",
            "No of paras: 3\n",
            "No of sentences: 7\n",
            "No of words: 166\n",
            "Label: 1\n",
            "Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\n",
            "No of paras: 4\n",
            "No of sentences: 11\n",
            "No of words: 138\n",
            "Label: 0\n",
            "Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.\n",
            "No of paras: 5\n",
            "No of sentences: 16\n",
            "No of words: 230\n",
            "Label: 1\n",
            "2470\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization and Preprocessing"
      ],
      "metadata": {
        "id": "KvZEAdZKt39i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of stopwords (overused words that could lead to overfitting)\n",
        "stops=set(stopwords.words('english'))\n",
        "capstops=[word.capitalize() for word in stops]\n",
        "stops.update(capstops)\n",
        "stops=list(stops)\n",
        "\n",
        "# Stemmer and Lemmatizer for normalizing the words to root words\n",
        "stemmer=PorterStemmer()\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "\n",
        "def custom_tokenize(text):\n",
        "  text=re.sub('<.*>', '', text) # Filter out html tags like <br/>\n",
        "  tokens=list(tokenize(text))\n",
        "  tokens=[token for token in tokens if token not in stops]\n",
        "  # can do lower case as normalization\n",
        "  # tokens=[stemmer.stem(token) for token in tokens]\n",
        "  # tokens=[lemmatizer.lemmatize(token) for token in tokens]\n",
        "  return tokens\n",
        "\n",
        "for i in range(5) :\n",
        "  rev=df.iloc[i]['review']\n",
        "  print(custom_tokenize(rev))"
      ],
      "metadata": {
        "id": "K9GWl9BQtqL8",
        "outputId": "ed17b425-fdda-4923-9e25-b59f12c0f2ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "up an can Just couldn No ll Couldn't Myself there any don't It Don Which mustn't Such Don't yours hadn ['One', 'reviewers', 'mentioned', 'watching', 'Oz', 'episode', 'hooked', 'right', 'exactly', 'happened', 'would', 'say', 'main', 'appeal', 'show', 'due', 'fact', 'goes', 'shows', 'dare', 'Forget', 'pretty', 'pictures', 'painted', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romance', 'OZ', 'mess', 'around', 'first', 'episode', 'ever', 'saw', 'struck', 'nasty', 'surreal', 'say', 'ready', 'watched', 'developed', 'taste', 'Oz', 'got', 'accustomed', 'high', 'levels', 'graphic', 'violence', 'violence', 'injustice', 'crooked', 'guards', 'sold', 'nickel', 'inmates', 'kill', 'order', 'get', 'away', 'well', 'mannered', 'middle', 'class', 'inmates', 'turned', 'prison', 'bitches', 'due', 'lack', 'street', 'skills', 'prison', 'experience', 'Watching', 'Oz', 'may', 'become', 'comfortable', 'uncomfortable', 'viewing', 'thats', 'get', 'touch', 'darker', 'side']\n",
            "['wonderful', 'little', 'production', 'realism', 'really', 'comes', 'home', 'little', 'things', 'fantasy', 'guard', 'rather', 'use', 'traditional', 'dream', 'techniques', 'remains', 'solid', 'disappears', 'plays', 'knowledge', 'senses', 'particularly', 'scenes', 'concerning', 'Orton', 'Halliwell', 'sets', 'particularly', 'flat', 'Halliwell', 'murals', 'decorating', 'every', 'surface', 'terribly', 'well', 'done']\n",
            "['thought', 'wonderful', 'way', 'spend', 'time', 'hot', 'summer', 'weekend', 'sitting', 'air', 'conditioned', 'theater', 'watching', 'light', 'hearted', 'comedy', 'plot', 'simplistic', 'dialogue', 'witty', 'characters', 'likable', 'even', 'well', 'bread', 'suspected', 'serial', 'killer', 'may', 'disappointed', 'realize', 'Match', 'Point', 'Risk', 'Addiction', 'thought', 'proof', 'Woody', 'Allen', 'still', 'fully', 'control', 'style', 'many', 'us', 'grown', 'love', 'may', 'crown', 'jewel', 'career', 'wittier', 'Devil', 'Wears', 'Prada', 'interesting', 'Superman', 'great', 'comedy', 'go', 'see', 'friends']\n",
            "['Basically', 'family', 'little', 'boy', 'Jake', 'thinks', 'zombie', 'closet', 'parents', 'fighting', 'time', 'well', 'playing', 'parents', 'descent', 'dialogs', 'shots', 'Jake', 'ignore']\n",
            "['Petter', 'Mattei', 'Love', 'Time', 'Money', 'visually', 'stunning', 'film', 'watch', 'Mr', 'Mattei', 'offers', 'us', 'vivid', 'portrait', 'human', 'relations', 'movie', 'seems', 'telling', 'us', 'money', 'power', 'success', 'people', 'different', 'situations', 'encounter', 'wish', 'Mr', 'Mattei', 'good', 'luck', 'await', 'anxiously', 'next', 'work']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-Test Split"
      ],
      "metadata": {
        "id": "gB144P43QO1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train1 = df.sample(frac=0.9, random_state=25)\n",
        "train = train1.sample(frac=0.8889, random_state=25)\n",
        "valid = train1.drop(train.index)\n",
        "test = df.drop(train1.index)"
      ],
      "metadata": {
        "id": "rJeOHMNMQSwg",
        "outputId": "a492b8e8-c904-4530-e9bf-5ff026843515",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 2)\n",
            "(5000, 2)\n",
            "(5000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorization and Mapping to a Vocabulary"
      ],
      "metadata": {
        "id": "ncHDXghmP0ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "counter = collections.Counter()\n",
        "for _, row in train.iterrows():\n",
        "  counter.update(custom_tokenize(row['review']))\n",
        "  # if _%1000==0:\n",
        "  #   print(_, end=' ')\n"
      ],
      "metadata": {
        "id": "GGD3PLGBPybn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Min_frequency to filter rare words\n",
        "min_freq = 5\n",
        "specials=[\"<unk>\", \"<pad>\"]\n",
        "train_vocab = vocab(counter, min_freq=min_freq, specials=specials)\n",
        "train_vocab.set_default_index(train_vocab[\"<pad>\"])\n",
        "for i in range(5) :\n",
        "  rev=df.iloc[i]['review']\n",
        "  tokens=custom_tokenize(rev)\n",
        "  for w in tokens:\n",
        "    print(train_vocab[w], w, end=' ')\n",
        "  print()"
      ],
      "metadata": {
        "id": "ScFmzM_0gTLm",
        "outputId": "9025292f-9768-4f99-c902-4c52d0eaf2ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "584 One 2261 reviewers 2906 mentioned 253 watching 8521 Oz 1079 episode 2100 hooked 308 right 6285 exactly 1173 happened 265 would 333 say 25 main 2675 appeal 258 show 1033 due 186 fact 1449 goes 660 shows 3212 dare 13519 Forget 506 pretty 1114 pictures 1113 painted 2010 mainstream 857 audiences 612 forget 6301 charm 612 forget 4876 romance 10492 OZ 3112 mess 321 around 84 first 1079 episode 383 ever 1051 saw 3989 struck 965 nasty 6778 surreal 333 say 5664 ready 385 watched 341 developed 1376 taste 8521 Oz 375 got 1562 accustomed 62 high 2651 levels 1637 graphic 930 violence 930 violence 12241 injustice 11228 crooked 17533 guards 4003 sold 26192 nickel 8475 inmates 2905 kill 1262 order 48 get 1016 away 338 well 7918 mannered 466 middle 3059 class 8475 inmates 685 turned 2902 prison 29802 bitches 1033 due 836 lack 764 street 7906 skills 2902 prison 2168 experience 670 Watching 8521 Oz 1222 may 1086 become 1801 comfortable 7792 uncomfortable 485 viewing 2475 thats 48 get 2963 touch 9612 darker 1602 side \n",
            "483 wonderful 176 little 192 production 13155 realism 202 really 294 comes 1132 home 176 little 11 things 455 fantasy 4417 guard 707 rather 932 use 8233 traditional 4546 dream 4276 techniques 3196 remains 342 solid 7767 disappears 41 plays 5434 knowledge 4944 senses 655 particularly 1578 scenes 351 concerning 1 Orton 29096 Halliwell 947 sets 655 particularly 4369 flat 29096 Halliwell 1 murals 1 decorating 985 every 2002 surface 3670 terribly 338 well 369 done \n",
            "272 thought 483 wonderful 290 way 817 spend 318 time 4650 hot 2082 summer 8785 weekend 5899 sitting 3432 air 13313 conditioned 4212 theater 253 watching 970 light 7416 hearted 403 comedy 96 plot 7330 simplistic 101 dialogue 8557 witty 26 characters 1825 likable 43 even 338 well 6847 bread 20140 suspected 607 serial 608 killer 1222 may 882 disappointed 1116 realize 24486 Match 2459 Point 26280 Risk 1 Addiction 272 thought 2367 proof 4218 Woody 4219 Allen 1128 still 3042 fully 5378 control 1219 style 406 many 218 us 7390 grown 164 love 1222 may 15885 crown 3406 jewel 872 career 1 wittier 2895 Devil 1 Wears 1 Prada 1790 interesting 13743 Superman 12 great 403 comedy 1543 go 67 see 380 friends \n",
            "6243 Basically 1048 family 176 little 1921 boy 2718 Jake 1629 thinks 4143 zombie 14268 closet 1768 parents 5232 fighting 318 time 338 well 203 playing 1768 parents 4076 descent 10802 dialogs 2662 shots 2718 Jake 4981 ignore \n",
            "1 Petter 14004 Mattei 664 Love 4194 Time 12639 Money 3695 visually 4409 stunning 5 film 302 watch 718 Mr 14004 Mattei 2335 offers 218 us 14209 vivid 1663 portrait 3552 human 15437 relations 91 movie 1230 seems 1078 telling 218 us 416 money 2819 power 1229 success 558 people 1076 different 1278 situations 7317 encounter 2918 wish 718 Mr 14004 Mattei 55 good 1607 luck 14891 await 10800 anxiously 654 next 121 work \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}