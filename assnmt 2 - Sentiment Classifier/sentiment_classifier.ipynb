{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sagnik-Nandi/PDFQueryBot---Chatbot-over-PDFs-using-RAG/blob/main/assnmt%202%20-%20Sentiment%20Classifier/sentiment_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data and Installing Dependencies"
      ],
      "metadata": {
        "id": "3SbZLlw3ts3B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "C87F18KQMVAb",
        "outputId": "e04ba5ab-f834-4a9c-a4f6-5c0ae2c61aeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llTC1NIlPQIb",
        "outputId": "18d305ed-3ce3-42b7-e2f8-c9d8c5bf9b2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls drive/MyDrive/'Colab Notebooks'/'WiDS 2024'\n",
        "!pip uninstall torchtext torch -y\n",
        "!pip install torch==2.2.0 torchtext==0.17.0\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchtext import datasets\n",
        "# import torchtext\n",
        "# from torchtext.data.utils import get_tokenizer\n",
        "# from torchtext.vocab import build_vocab_from_iterator\n",
        "# from nltk\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "jvpQUnsAMy5E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "d53bd301-f073-4e91-a41b-26f58991c48d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Field' from 'torchtext.data' (/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d557b07dbd8b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBucketIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# import torchtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# from torchtext.data.utils import get_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Field' from 'torchtext.data' (/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GsI8mUYP7_NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"drive/MyDrive/Colab Notebooks/WiDS 2024/reviews.csv\")\n",
        "for i in range(5):\n",
        "  rev=df.iloc[i]['review']\n",
        "  # iloc gives the i'th row, if you dont use iloc it will try to find a column/feature named i and raise an error\n",
        "  print(rev)\n",
        "  print(\"No of paras:\", len(rev.split('<br /><br />')))\n",
        "  print(\"No of sentences:\", len(rev.split('.')))\n",
        "  print(\"No of words:\", len(rev.split()))\n",
        "  print(\"Label:\", df.iloc[i]['sentiment'])\n",
        "\n",
        "print(max(df['review'].apply(lambda x: len(x.split()))))\n",
        "print(min(df['review'].apply(lambda x: len(x.split()))))"
      ],
      "metadata": {
        "id": "w3BLK6RbNohR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization and Preprocessing"
      ],
      "metadata": {
        "id": "KvZEAdZKt39i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for padding, need to set a max length parameter\n",
        "max_len=200\n",
        "# basic english tokenizer splits and turn into lower case\n",
        "# explore other tokenizers like punctuation removing, stop word removing,\n",
        "# also need to remove <br\\> token, insert special tokens like <pad> and <eos>\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def tokenize(data):\n",
        "  tokens=tokenizer(data['review'])[0:max_len]\n",
        "  length=len(tokens)\n",
        "  return {\"tokens\":tokens, \"len\": length}"
      ],
      "metadata": {
        "id": "K9GWl9BQtqL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data=torch.from_numpy(df.values)\n",
        "# class CustomTextDataset\n",
        "# data=CustomTextDataset(df)\n",
        "# train, valid, test=random_split(df, [40000, 5000, 5000])\n",
        "# train=df.iloc[0:40000]\n",
        "# valid=df.iloc[40000:45000]\n",
        "# test=df.iloc[45000:]\n",
        "\n",
        "# train=train.map(tokenize)\n",
        "# valid=valid.map(tokenize)\n",
        "# test=test.map(tokenize)"
      ],
      "metadata": {
        "id": "hx0dK-Vc0_lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#-----------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "St1RhjEJPkcA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SMZQrysXPoiJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}